{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8739155581260845\n",
      "[{'buying': [5.084662466324277e-18, 0.9070711523587058, 0.00048320302528534595, 0.0004104840181710014, 0.0920351605978378], 'vhigh': [100.04353817692618, 42.816117782546755, 99.03427814453093, 100.34680691521075, 89.75925898078539], 'high': [103.20822716901004, 40.19303784324737, 94.26715048534543, 98.49424431640112, 95.83734018599614], 'med': [102.53912734440698, 43.28009700039003, 96.92476066256947, 95.44843880996184, 93.80757618267192], 'low': [102.49241664855921, 40.43610073750807, 99.06726030728012, 91.96814733072887, 98.0360749759238]}, {'maint': [5.084662466324277e-18, 0.9070711523587058, 0.00048320302528534595, 0.0004104840181710014, 0.0920351605978378], 'vhigh': [100.60282263265194, 40.434472900752056, 102.25631966102797, 94.08428546815328, 94.62209933741485], 'high': [98.82930594256193, 41.24372117059482, 99.32039759931962, 97.60246720130793, 95.00410808621562], 'med': [107.25081754382408, 41.68684768945719, 91.73141956283116, 97.34253672178173, 93.9883784821059], 'low': [101.60036321986445, 43.36031160288805, 95.9853127765473, 97.22834798105936, 93.8256644196408]}, {'doors': [5.084662466324277e-18, 0.9070711523587058, 0.00048320302528534595, 0.0004104840181710014, 0.0920351605978378], '2': [103.75802139901361, 42.85105903008417, 94.2333989975651, 96.37222299634428, 94.78529757699287], '3': [100.9166225694353, 42.40277296025332, 98.97076312339168, 95.90849864396289, 93.80134270295692], '4': [105.22173101088146, 42.13961989128523, 95.98859412576067, 96.59270515706002, 92.05734981501271], '5more': [98.38693435957205, 39.33190148206936, 100.10069335300858, 97.38421057493514, 96.7962602304148]}, {'persons': [5.084662466324277e-18, 0.9070711523587058, 0.00048320302528534595, 0.0004104840181710014, 0.0920351605978378], '2': [137.1405339718446, 54.36162421150213, 130.08325173245106, 127.66774145537232, 126.74684862882992], '4': [131.22476531896962, 55.19971617018609, 126.66222850303433, 132.02141718706562, 130.89187282074434], 'more': [139.91801004808815, 57.16401298200395, 132.54796936424066, 126.5684787298646, 119.80152887580287]}, {'lug_boot': [5.084662466324277e-18, 0.9070711523587058, 0.00048320302528534595, 0.0004104840181710014, 0.0920351605978378], 'small': [138.08615687982703, 56.70154844729335, 124.93372877180133, 128.9702184292664, 127.30834747181193], 'med': [135.19549554472962, 55.15352648332275, 131.0212767504783, 129.64073550768634, 124.988965713783], 'big': [135.00165691434572, 54.870278433076074, 133.33844407744647, 127.64668343534977, 125.14293713978218]}, {'safety': [5.084662466324277e-18, 0.9070711523587058, 0.00048320302528534595, 0.0004104840181710014, 0.0920351605978378], 'low': [140.98573995248725, 54.09576823375755, 130.38205581631445, 125.55404991137624, 124.98238608606466], 'med': [134.61489438092542, 54.20392622468728, 128.50029410480136, 131.64320972156798, 127.03767556801778], 'high': [132.68267500548967, 58.42565890524734, 130.4110996786102, 129.06037773935833, 125.42018867129464]}]\n",
      "0.7004048582995951\n",
      "0.06477732793522267\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "import random\n",
    "from operator import itemgetter\n",
    "\n",
    "CSV_FILE = 'Cars.csv'\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, prior_count, total_count, posterior_counts, attribute_counts):\n",
    "        self.prior_count = prior_count\n",
    "        self.total_count = total_count\n",
    "        self.posterior_counts = posterior_counts\n",
    "        self.attribute_counts = attribute_counts\n",
    "\n",
    "def remove_class_column(data):\n",
    "    new_data = []\n",
    "    for row in data:\n",
    "        new_data.append(row[:-1])\n",
    "\n",
    "    return new_data\n",
    "\n",
    "def normalize_row(row):\n",
    "    #sum up the values        \n",
    "    non_normalized_sum = 0\n",
    "    for j in range(len(row)):\n",
    "        non_normalized_sum += row[j]\n",
    "\n",
    "    #normalize to make them equal to 1\n",
    "    for j in range(len(row)):\n",
    "        row[j] = row[j]/non_normalized_sum\n",
    "\n",
    "    return row\n",
    "\n",
    "def return_classes(data):\n",
    "    class_column = len(data[0])-1\n",
    "    classes = []\n",
    "    #count number of classes in labelled data\n",
    "    temp_class_dict = {}\n",
    "    for row in data:\n",
    "        if row[class_column] not in temp_class_dict:\n",
    "            classes.append(row[class_column])\n",
    "            temp_class_dict[row[class_column]] = True\n",
    "    \n",
    "    return classes\n",
    "\n",
    "# This function should open a data file in csv, and transform it into a usable format \n",
    "def preprocess(name):\n",
    "    data = []\n",
    "\n",
    "    #read CSV into array\n",
    "    with open(name) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "# This function should build a supervised NB model\n",
    "def train_supervised(data):\n",
    "    #find last column\n",
    "    class_column = len(data[0])-1\n",
    "\n",
    "    #store counts of all priors and a total count of instances\n",
    "    prior_count = {}\n",
    "    total_count = 0\n",
    "    for row in data:\n",
    "        if row[class_column] in prior_count:\n",
    "            prior_count[row[class_column]] += 1\n",
    "        else:\n",
    "            prior_count[row[class_column]] = 1\n",
    "        \n",
    "        total_count += 1\n",
    "\n",
    "    #a 1D array of dictionaries holding posterior values\n",
    "    posterior_counts = [dict() for x in range(class_column)]\n",
    "    #a 1D array holding the number of different attribute types per attribute\n",
    "    attribute_counts = [0]*class_column\n",
    "    \n",
    "    #for each attribute  \n",
    "    for i in range(class_column):\n",
    "        #keep track of attribute types we've seen\n",
    "        temp_attribute_dict = {}\n",
    "        #for each instance\n",
    "        for j in range(len(data)):\n",
    "            #concatenate attribute and its corresponding instance class as a key\n",
    "            attribute_class_key = data[j][i] + data[j][class_column]\n",
    "            #store counts in dictionary\n",
    "            if attribute_class_key in posterior_counts[i]:\n",
    "                posterior_counts[i][attribute_class_key] += 1\n",
    "            else:\n",
    "                posterior_counts[i][attribute_class_key] = 1\n",
    "\n",
    "            #count number of attribute values\n",
    "            if data[j][i] not in temp_attribute_dict:\n",
    "                attribute_counts[i] += 1\n",
    "                temp_attribute_dict[data[j][i]] = True\n",
    "        \n",
    "    #stores all relevant values in a model class\n",
    "    model = Model(prior_count, total_count, posterior_counts, attribute_counts)\n",
    "\n",
    "    return model\n",
    "\n",
    "# This function should predict the class for a set of instances, based on a trained model \n",
    "def predict_supervised(model, instances):\n",
    "    predictions = []\n",
    "\n",
    "    for instance in instances:\n",
    "        prediction = []\n",
    "        for prior_class in list(model.prior_count.keys()):\n",
    "            #check if there are unseen events\n",
    "            unseen = 0\n",
    "            for i in range(len(instance)):\n",
    "                attribute_class_key = instance[i] + prior_class\n",
    "                if attribute_class_key not in model.posterior_counts[i]:\n",
    "                    unseen = 1\n",
    "                    break\n",
    "\n",
    "            sum = math.log(model.prior_count[prior_class]/model.total_count)\n",
    "            for i in range(len(instance)):\n",
    "                attribute_class_key = instance[i] + prior_class\n",
    "                if attribute_class_key in model.posterior_counts[i]:\n",
    "                    #print (attribute_class_key, model.posterior_counts[i][attribute_class_key], \"/\", model.prior_count[prior_class], \"op\", model.attribute_counts[i])\n",
    "                    sum += math.log((model.posterior_counts[i][attribute_class_key]+unseen)/(model.prior_count[prior_class]+unseen*model.attribute_counts[i]))\n",
    "                else:\n",
    "                    sum += math.log(1/(model.prior_count[prior_class]+model.attribute_counts[i]))\n",
    "                \n",
    "            class_tuple = (prior_class, sum)\n",
    "            prediction.append(class_tuple)\n",
    "\n",
    "        prediction.sort(key=itemgetter(1), reverse=True)\n",
    "        predictions.append(prediction)      \n",
    "            \n",
    "    return predictions\n",
    "\n",
    "# This function should evaluate a set of predictions, in a supervised context \n",
    "def evaluate_supervised(data, predictions):\n",
    "    #find last column\n",
    "    class_column = len(data[0])-1\n",
    "\n",
    "    correct_predictions = 0\n",
    "    for i in range(len(data)):\n",
    "        if data[i][class_column] == predictions[i][0][0]:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    return correct_predictions/len(data)\n",
    "\n",
    "# This function should build an unsupervised NB model \n",
    "def train_unsupervised(data):\n",
    "    #find last column\n",
    "    class_column = len(data[0])-1\n",
    "\n",
    "    num_classes = len(return_classes(data))\n",
    "    class_probabilities = [[] for i in range(len(data))]\n",
    "\n",
    "    #remove class column\n",
    "    data = remove_class_column(data)\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        class_probability_row = [0]*num_classes\n",
    "\n",
    "        #assign random values to each class             \n",
    "        for j in range(num_classes):\n",
    "            class_probability_row[j] = random.random()\n",
    "\n",
    "        #normalize and store in array\n",
    "        class_probabilities[i] = normalize_row(class_probability_row)\n",
    "\n",
    "    for i in range(50):\n",
    "        prior_count = [0]*num_classes\n",
    "        for class_probability_row in class_probabilities:\n",
    "            for i in range(num_classes):\n",
    "                prior_count[i] += class_probability_row[i]\n",
    "\n",
    "        #a 1D array of dictionaries holding posterior values\n",
    "        posterior_counts = [dict() for x in range(len(data[0]))]    \n",
    "\n",
    "        for i in range(len(data[0])):\n",
    "            for j in range(len(data)):\n",
    "                if data[j][i] not in posterior_counts[i]:\n",
    "                    posterior_counts[i][data[j][i]] = [0]*num_classes\n",
    "\n",
    "                for k in range(num_classes):\n",
    "                    posterior_counts[i][data[j][i]][k] += class_probabilities[j][k]\n",
    "\n",
    "        for i in range(len(data)):\n",
    "            for j in range(num_classes):\n",
    "                if class_probabilities[i][j] > 0.9999999 or class_probabilities[i][j] < 0.00000001:\n",
    "                    break\n",
    "\n",
    "                sum = math.log(prior_count[j]/len(data))\n",
    "                for k in range(len(data[0])):\n",
    "                    #print(data[i][k], posterior_counts[k][data[i][k]][j],prior_count[j])                    \n",
    "                    sum += math.log((posterior_counts[k][data[i][k]][j])/prior_count[j])\n",
    "\n",
    "                class_probabilities[i][j] = math.exp(sum)\n",
    "\n",
    "            class_probabilities[i] = normalize_row(class_probabilities[i])\n",
    "\n",
    "    print(posterior_counts)\n",
    "\n",
    "    model = Model(prior_count, len(data), posterior_counts, [])\n",
    "\n",
    "    return model\n",
    "\n",
    "# This function should predict the class distribution for a set of instances, based on a trained model\n",
    "def predict_unsupervised(model, instances):\n",
    "    predictions = []\n",
    "\n",
    "    for instance in instances:\n",
    "        prediction = [0]*len(model.prior_count)\n",
    "        for i in range(len(model.prior_count)):\n",
    "            sum = math.log(model.prior_count[i]/model.total_count)\n",
    "            for k in range(len(instance)):\n",
    "                sum += math.log((model.posterior_counts[k][instance[k]][i])/model.prior_count[i])\n",
    "            prediction[i] = sum\n",
    "        predictions.append(prediction)   \n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# This function should evaluate a set of predictions, in an unsupervised manner\n",
    "def evaluate_unsupervised(data, predictions):\n",
    "    #find last column\n",
    "    class_column = len(data[0])-1\n",
    "    classes = return_classes(data)\n",
    "\n",
    "    confusion_matrix = [[0 for i in range(len(predictions[0]))] for j in range(len(predictions[0]))]\n",
    "\n",
    "    \n",
    "\n",
    "    for i, current_class in enumerate(classes):\n",
    "        for j in range(len(classes)):\n",
    "            for k in range(len(predictions)):                \n",
    "                if data[k][class_column] == current_class and j == predictions[k].index(max(predictions[k])):\n",
    "                    confusion_matrix[i][j] += 1\n",
    "    \n",
    "    maxes = [0]*len(classes)\n",
    "    \n",
    "    for j in range(len(classes)):\n",
    "        current_max = 0\n",
    "        for i in range(len(classes)):\n",
    "            if current_max < confusion_matrix[i][j]:\n",
    "                current_max = confusion_matrix[i][j]\n",
    "        maxes[j] = current_max\n",
    "\n",
    "    return sum(maxes)/len(predictions)\n",
    "\n",
    "def evaluate_unsupervised_deterministic(data, predictions):\n",
    "    #find last column\n",
    "    class_column = len(data[0])-1\n",
    "    classes = return_classes(data)\n",
    "\n",
    "    correct = 0\n",
    "    for i, row in enumerate(data):\n",
    "        if row[class_column] == classes[predictions[i].index(max(predictions[i]))]:\n",
    "            correct += 1\n",
    "\n",
    "    return correct/len(predictions)\n",
    "\n",
    "def main():\n",
    "    data = preprocess(CSV_FILE)\n",
    "    model = train_supervised(data)\n",
    "    predictions = predict_supervised(model, remove_class_column(data))\n",
    "    print(evaluate_supervised(data, predictions))\n",
    "\n",
    "    model = train_unsupervised(data)\n",
    "    predictions = predict_unsupervised(model, remove_class_column(data))\n",
    "    print(evaluate_unsupervised(data, predictions))\n",
    "    print(evaluate_unsupervised_deterministic(data, predictions))\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "820d0c5b45dce294a1235b7537830c47db2bb68d3c777587171b387e99a7b836"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
