{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcAdrMSvPNE0"
      },
      "source": [
        "Q1) Consider the following Dataset containing information regarding alcohol consumption in different countries. \n",
        "An analyst performs different operations to carry out certain tasks to help the analyst in performing the task.\n",
        "\n",
        " Which continent drinks more Wine on average? [2 marks]\n",
        "\n",
        " For each continent print the statistics for Beer consumption. [2 mark]\n",
        " \n",
        " Print the median alcohol consumption per continent for every column. [1 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lwRKJiBBPSIj",
        "outputId": "3595a1b3-ff36-4d44-ab50-46f4eaeeaefb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('drinks.csv')\n",
        "df1_copy = df1 \n",
        "#df1_copy.head()\n",
        "\n",
        "#1st ques code :\n",
        "\n",
        "x = df1_copy.groupby('continent').agg(\n",
        "    {\n",
        "        'wine_servings' : 'mean'\n",
        "    }\n",
        ")\n",
        "print(x.sort_values('wine_servings'))\n",
        "print(\"\\n\")\n",
        "\n",
        "#2nd ques code: \n",
        "y = df1_copy.groupby('continent').agg(\n",
        "    {\n",
        "        'beer_servings' : 'describe'\n",
        "    }\n",
        ")\n",
        "print(y)\n",
        "print(\"\\n\")\n",
        "\n",
        "#3rd ques code :\n",
        "\n",
        "z = df1_copy.groupby('continent').median()\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER-P5GQEPYHc"
      },
      "source": [
        "Q2) Consider a Euro 2012 football tournament.\n",
        "\n",
        "\n",
        "Football analysts decide certain criteria in order to decide which team has a good chance to win this cup. Your task is to help those analysts by performing some tasks given below.\n",
        "\n",
        " Find the teams who are participating in this tournament. [1 marks]\n",
        "\n",
        " Find the shooting accuracy of all the teams that have scored more than 5 goals. [1 marks]\n",
        "\n",
        " Find the total number of goals scored in the tournament. [1 marks]\n",
        "\n",
        " Sort the teams on the basis of goals scored(non-ascending order) [1 marks]\n",
        " \n",
        " Find the team with the most number of red cards. [1 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iUWwAmEbPdVr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df2 = pd.read_csv('Euro_2012_stats_TEAM.csv')\n",
        "# df2\n",
        "#code for 1st ques :\n",
        "print(df2.Team)\n",
        "print(df2.shape[0])\n",
        "print(\"\\n\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "#code for 2nd ques :\n",
        "\n",
        "accuracy = df2.loc[df2[\"Goals\"]>5,[\"Team\",\"Shooting Accuracy\"]]\n",
        "print(accuracy)\n",
        "print(\"\\n\")\n",
        "print(\"----------------------------------------------------\")\n",
        "\n",
        "#code for 3rd ques :\n",
        "\n",
        "print(df2[\"Goals\"].sum())\n",
        "print(\"\\n\")\n",
        "print(\"-------------------------------------------------------\")\n",
        "\n",
        "#code for 4th ques :\n",
        "\n",
        "sortedDf = df2.loc[:,[\"Team\",\"Goals\"]]\n",
        "print(sortedDf.sort_values(\"Goals\",ascending = False))\n",
        "print(\"\\n\")\n",
        "print(\"--------------------------------------------------------\")\n",
        "\n",
        "\n",
        "#code for 5th ques :\n",
        "\n",
        "redCards = df2.loc[:,[\"Team\",\"Red Cards\"]]\n",
        "print(redCards[redCards[\"Red Cards\"]==redCards[\"Red Cards\"].max()])\n",
        "print(\"\\n\")\n",
        "print(\"---------------------------------------------------------\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7NNvvV8PhMN"
      },
      "source": [
        "Q3) Consider the given breast cancer dataset from the given google drive link, the last column has the target variable \n",
        "\n",
        "\n",
        "(2 classes: \"B\" for benign and \"M\" for malignant) and the remaining columns have the features.\n",
        "\n",
        "\n",
        "Implement the decision tree algorithm from scratch. You can use the Gini index to decide on the splitting attribute on the breast cancer dataset. Make use of only NumPy, pandas. Calculate the accuracy of the decision tree. [10 marks]\n",
        "\n",
        "\n",
        "Data set info : (the second column is the class attribute)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUy42wiVPklM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df3 = pd.read_csv('wdbc.data')\n",
        "#print(df3)\n",
        "# df3.head(10)\n",
        "class Node():\n",
        "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, info_gain=None, value=None):\n",
        "        ''' constructor ''' \n",
        "        \n",
        "        # for decision nodes :\n",
        "        self.feature_index = feature_index\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.info_gain = info_gain\n",
        "        \n",
        "        # for leaf nodes :\n",
        "        self.value = value\n",
        "\n",
        "\n",
        "# The following would be the code for tree class :\n",
        "\n",
        "class DecisionTreeClassifier():\n",
        "    def __init__(self, min_samples_split=2, max_depth=2):\n",
        "        ''' constructor '''\n",
        "        \n",
        "        # initialize the root of the tree \n",
        "        self.root = None\n",
        "        \n",
        "        # stopping conditions\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    def build_tree(self, dataset, curr_depth=0):\n",
        "        \n",
        "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
        "        num_samples, num_features = np.shape(X)\n",
        "        \n",
        "        # split until stopping conditions are met\n",
        "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
        "            # find the best split\n",
        "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
        "            # check if information gain is positive\n",
        "            if best_split[\"info_gain\"]>0:\n",
        "                # recur left\n",
        "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
        "                # recur right\n",
        "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
        "                # return decision node\n",
        "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
        "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
        "        \n",
        "        # compute leaf node\n",
        "        leaf_value = self.calculate_leaf_value(Y)\n",
        "        # return leaf node\n",
        "        return Node(value=leaf_value)\n",
        "    \n",
        "    def get_best_split(self, dataset, num_samples, num_features):\n",
        "        ''' function to find the best split '''\n",
        "        \n",
        "        # dictionary to store the best split\n",
        "        best_split = {}\n",
        "        max_info_gain = -float(\"inf\")\n",
        "        \n",
        "        # loop over all the features\n",
        "        for feature_index in range(num_features):\n",
        "            feature_values = dataset[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            # loop over all the feature values present in the data\n",
        "            for threshold in possible_thresholds:\n",
        "                # get current split\n",
        "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
        "                # check if childs are not null\n",
        "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
        "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
        "                    # compute information gain\n",
        "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
        "                    # update the best split if needed\n",
        "                    if curr_info_gain>max_info_gain:\n",
        "                        best_split[\"feature_index\"] = feature_index\n",
        "                        best_split[\"threshold\"] = threshold\n",
        "                        best_split[\"dataset_left\"] = dataset_left\n",
        "                        best_split[\"dataset_right\"] = dataset_right\n",
        "                        best_split[\"info_gain\"] = curr_info_gain\n",
        "                        max_info_gain = curr_info_gain\n",
        "                        \n",
        "        # return best split\n",
        "        return best_split\n",
        "    \n",
        "    def split(self, dataset, feature_index, threshold):\n",
        "        ''' function to split the data '''\n",
        "        \n",
        "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
        "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
        "        return dataset_left, dataset_right\n",
        "    \n",
        "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
        "        ''' function to compute information gain '''\n",
        "        \n",
        "        weight_l = len(l_child) / len(parent)\n",
        "        weight_r = len(r_child) / len(parent)\n",
        "        if mode==\"gini\":\n",
        "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
        "        else:\n",
        "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
        "        return gain\n",
        "    \n",
        "    def entropy(self, y):\n",
        "        ''' function to compute entropy '''\n",
        "        \n",
        "        class_labels = np.unique(y)\n",
        "        entropy = 0\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y == cls]) / len(y)\n",
        "            entropy += -p_cls * np.log2(p_cls)\n",
        "        return entropy\n",
        "    \n",
        "    def gini_index(self, y):\n",
        "        ''' function to compute gini index '''\n",
        "        \n",
        "        class_labels = np.unique(y)\n",
        "        gini = 0\n",
        "        for cls in class_labels:\n",
        "            p_cls = len(y[y == cls]) / len(y)\n",
        "            gini += p_cls**2\n",
        "        return 1 - gini\n",
        "        \n",
        "    def calculate_leaf_value(self, Y):\n",
        "        ''' function to compute leaf node '''\n",
        "        \n",
        "        Y = list(Y)\n",
        "        return max(Y, key=Y.count)\n",
        "    \n",
        "    def print_tree(self, tree=None, indent=\" \"):\n",
        "        ''' function to print the tree '''\n",
        "        \n",
        "        if not tree:\n",
        "            tree = self.root\n",
        "\n",
        "        if tree.value is not None:\n",
        "            print(tree.value)\n",
        "\n",
        "        else:\n",
        "            print(\"X_\"+str(tree.feature_index), \"<=\", tree.threshold, \"?\", tree.info_gain)\n",
        "            print(\"%sleft:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.left, indent + indent)\n",
        "            print(\"%sright:\" % (indent), end=\"\")\n",
        "            self.print_tree(tree.right, indent + indent)\n",
        "    \n",
        "    def fit(self, X, Y):\n",
        "        ''' function to train the tree '''\n",
        "        \n",
        "        dataset = np.concatenate((X, Y), axis=1)\n",
        "        self.root = self.build_tree(dataset)\n",
        "    \n",
        "    def predict(self, X):\n",
        "        ''' function to predict new dataset '''\n",
        "        \n",
        "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
        "        return preditions\n",
        "    \n",
        "    def make_prediction(self, x, tree):\n",
        "        ''' function to predict a single data point '''\n",
        "        \n",
        "        if tree.value!=None: return tree.value\n",
        "        feature_val = x[tree.feature_index]\n",
        "        if feature_val<=tree.threshold:\n",
        "            return self.make_prediction(x, tree.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, tree.right)\n",
        "\n",
        "\n",
        "# The next few lines of code split the data set :\n",
        "\n",
        "X = df3.iloc[:, :-1].values\n",
        "Y = df3.iloc[:, -1].values.reshape(-1,1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=41)\n",
        "\n",
        "# The next few lines of code are for fitting the model :\n",
        "\n",
        "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=3)\n",
        "classifier.fit(X_train,Y_train)\n",
        "classifier.print_tree()\n",
        "\n",
        "# The last part of the question - calculating the accuracy score : we use sklearn.matrix module for that as it is allowed :\n",
        "\n",
        "Y_pred = classifier.predict(X_test) \n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, Y_pred)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
